{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4d90a8-c513-457d-9ca9-b93d53d25413",
   "metadata": {},
   "source": [
    "# Script 3 - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82928693-22e2-48f6-af48-1759daa51510",
   "metadata": {},
   "source": [
    "_Script by Tim Hebestreit, thebestr@smail.uni-koeln.de_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b0899-b14e-4043-b4eb-b212a678a46e",
   "metadata": {},
   "source": [
    "In this script we use a German BERT model pretrained for sentiment analysis. We utilize the transformers library from huggingface to load a model to analyze whether the articles have positive, neutral, or negative sentiment. The model runs are additionally logged using Weights and biases (W&B) for additional metrics and information about inference runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb39107b-2b80-4bd8-a6ff-8bf2d7cefcba",
   "metadata": {},
   "source": [
    "The needed packages are installed first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f2d1be-73d6-43eb-9a42-3bc576357e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.42.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.9.1)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.11/site-packages (0.23.1)\n",
      "Requirement already satisfied: weave in /opt/conda/lib/python3.11/site-packages (0.52.22)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.11/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.11/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.11/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: click>=8.0.1 in /opt/conda/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb) (3.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (4.24.3)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.47.0)\n",
      "Requirement already satisfied: diskcache==5.6.3 in /opt/conda/lib/python3.11/site-packages (from weave) (5.6.3)\n",
      "Requirement already satisfied: gql>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from gql[httpx]>=3.0.0->weave) (4.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.23.0 in /opt/conda/lib/python3.11/site-packages (from weave) (4.25.1)\n",
      "Requirement already satisfied: polyfile-weave in /opt/conda/lib/python3.11/site-packages (from weave) (0.5.7)\n",
      "Requirement already satisfied: tenacity!=8.4.0,>=8.3.0 in /opt/conda/lib/python3.11/site-packages (from weave) (9.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.2 in /opt/conda/lib/python3.11/site-packages (from gql>=3.0.0->gql[httpx]>=3.0.0->weave) (3.2.7)\n",
      "Requirement already satisfied: yarl<2.0,>=1.6 in /opt/conda/lib/python3.11/site-packages (from gql>=3.0.0->gql[httpx]>=3.0.0->weave) (1.9.2)\n",
      "Requirement already satisfied: backoff<3.0,>=1.11.1 in /opt/conda/lib/python3.11/site-packages (from gql>=3.0.0->gql[httpx]>=3.0.0->weave) (2.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.0 in /opt/conda/lib/python3.11/site-packages (from gql>=3.0.0->gql[httpx]>=3.0.0->weave) (4.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.27.0 in /opt/conda/lib/python3.11/site-packages (from gql[httpx]>=3.0.0->weave) (0.28.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.23.0->weave) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.23.0->weave) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.23.0->weave) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.23.0->weave) (0.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: abnf~=2.2.0 in /opt/conda/lib/python3.11/site-packages (from polyfile-weave->weave) (2.2.0)\n",
      "Requirement already satisfied: chardet>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from polyfile-weave->weave) (5.2.0)\n",
      "Requirement already satisfied: cint>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from polyfile-weave->weave) (1.0.0)\n",
      "Requirement already satisfied: fickling>=0.0.8 in /opt/conda/lib/python3.11/site-packages (from polyfile-weave->weave) (0.1.5)\n",
      "Requirement already satisfied: graphviz>=0.20.1 in /opt/conda/lib/python3.11/site-packages (from polyfile-weave->weave) (0.21)\n",
      "Requirement already satisfied: intervaltree>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from polyfile-weave->weave) (3.1.0)\n",
      "Requirement already satisfied: kaitaistruct~=0.10 in /opt/conda/lib/python3.11/site-packages (from polyfile-weave->weave) (0.11)\n",
      "Requirement already satisfied: pdfminer.six<=20250506,>=20220524 in /opt/conda/lib/python3.11/site-packages (from polyfile-weave->weave) (20250506)\n",
      "Requirement already satisfied: Pillow>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from polyfile-weave->weave) (10.1.0)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /opt/conda/lib/python3.11/site-packages (from polyfile-weave->weave) (80.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.0->gql>=3.0.0->gql[httpx]>=3.0.0->weave) (1.3.0)\n",
      "Requirement already satisfied: stdlib-list~=0.11.1 in /opt/conda/lib/python3.11/site-packages (from fickling>=0.0.8->polyfile-weave->weave) (0.11.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.27.0->gql[httpx]>=3.0.0->weave) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.27.0->gql[httpx]>=3.0.0->weave) (0.16.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from intervaltree>=2.4.0->polyfile-weave->weave) (2.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.11/site-packages (from pdfminer.six<=20250506,>=20220524->polyfile-weave->weave) (41.0.4)\n",
      "Requirement already satisfied: multidict>=4.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.6->gql>=3.0.0->gql[httpx]>=3.0.0->weave) (6.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six<=20250506,>=20220524->polyfile-weave->weave) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six<=20250506,>=20220524->polyfile-weave->weave) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch wandb weave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ffeb65-f226-48cb-9c82-879eabe3a573",
   "metadata": {},
   "source": [
    "Now we install the needed libraries that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c15bc7a-6a73-4bca-8a73-50cbe42d9790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 17:06:30.430885: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-22 17:06:33.733461: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-22 17:06:33.755016: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-22 17:06:37.045753: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-22 17:06:49.910037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORTS ---\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "import time\n",
    "import weave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46de73-6d47-497c-8e60-219ce270065e",
   "metadata": {},
   "source": [
    "The output from Script 2 (corpus.csv) is used as input for this script, which contains the parsed and processed corpus of German news articles. The output file, which is the corpus with added sentiment, is defined here as well.\n",
    "\n",
    "Further, we define a threshold for articles to be classified as positive or negative. This is done as the language in news articles is often pretty neutral, even when describing positive or negative events. An example could be \"Die Technologie birgt einige Risiken\", which is very likely to be classified as neutral, even though the statements talks about the technology in a negative fashion. By reducing the threshhold, more articles are being classified as positive or negative if the likelihood of them being in that category is sufficiently high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49e7944-2593-47c0-9c81-bb2ac5fab9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "\n",
    "INPUT_FILE = \"../data/csv/corpus.csv\"\n",
    "OUTPUT_FILE = \"../data/csv/corpus_with_sentiment.csv\"\n",
    "\n",
    "THRESHOLD_NEGATIVE = 0.35 \n",
    "THRESHOLD_POSITIVE = 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0572743d-5eb5-45da-9311-1d6ff3a0314d",
   "metadata": {},
   "source": [
    "The corpus data is imported, along with a quick look at its shape and first 5 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9267393-935a-404f-b524-a3be7bd95050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus data loaded. Initial shape: (54133, 9)\n",
      "                                  Source  \\\n",
      "0                            Focus-Money   \n",
      "1                       Berliner Zeitung   \n",
      "2  Broadcaster: SRF 08:08 AM MEZ/CET SRF   \n",
      "3                        dpa-AFX ProFeed   \n",
      "4                        VDI nachrichten   \n",
      "\n",
      "                                               Title  \\\n",
      "0  BUCHHALTUNGSPROGRAMME IM TEST; Software mit Gü...   \n",
      "1  Wie in Hollywood; Das Computerspiel \"Total War...   \n",
      "2  nano spezial: «... wollt Ihr ewig leben?» vom ...   \n",
      "3  IRW-News: Codebase Ventures Inc.: Pressland sc...   \n",
      "4                    Gesucht: Leitbild für Mobilität   \n",
      "\n",
      "                                                Text        Date  Word_Count  \\\n",
      "0  Die Buchhaltungssoftware von Lexware ist wie i...  2023-05-03        1914   \n",
      "1  VON FELIX FIRME Tao Ying und Mei Yun sind best...  2019-05-31         965   \n",
      "2  es ist alles nicht was Erhöhung Einzelheit sei...  2018-06-06        3204   \n",
      "3  IRW-PRESS: Codebase Ventures Inc.: Pressland s...  2019-04-10         964   \n",
      "4  Stuttgarter Symposium: Die Zukunft der Mobilit...  2019-04-05         991   \n",
      "\n",
      "   Is_IT_Source  Is_PR  Year  Month  \n",
      "0         False   True  2023      5  \n",
      "1         False   True  2019      5  \n",
      "2         False   True  2018      6  \n",
      "3         False   True  2019      4  \n",
      "4          True   True  2019      4  \n"
     ]
    }
   ],
   "source": [
    "# --- LOAD AND INSPECT CORPUS DATA ---\n",
    "\n",
    "if os.path.exists(INPUT_FILE):\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    print(f\"Corpus data loaded. Initial shape: {df.shape}\")\n",
    "    print(df.head(5))\n",
    "    \n",
    "else:\n",
    "    print(f\"Input file not found: {INPUT_FILE}\")\n",
    "    print(\"Please run Script 1 to generate raw data, and then run Script 2 to create corpus data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14de60-18be-4d20-ab60-bad552a9c627",
   "metadata": {},
   "source": [
    "W&B is used to track inference runs of this project. The config for that is set up here. Note that to run this script, you do not need to use W&B and can skip the login and authentication process. Also, we set whether the script is run using CPU or GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f43095-e8d5-477a-bd0c-3e6095f91e35",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthebestr\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/Hausarbeit/scripts/wandb/run-20251222_170725-vfjanwdk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thebestr/it-news-sentiment/runs/vfjanwdk' target=\"_blank\">bert-inference-full-run-sensitive</a></strong> to <a href='https://wandb.ai/thebestr/it-news-sentiment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thebestr/it-news-sentiment' target=\"_blank\">https://wandb.ai/thebestr/it-news-sentiment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thebestr/it-news-sentiment/runs/vfjanwdk' target=\"_blank\">https://wandb.ai/thebestr/it-news-sentiment/runs/vfjanwdk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Initializing weave.\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: thebestr.\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/thebestr/it-news-sentiment/weave\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/thebestr/it-news-sentiment/runs/vfjanwdk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb3f7b2ce10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- WEIGHTS AND BIASES CONFIG ---\n",
    "\n",
    "# The device used for this run is set. If your device supports CUDA, GPU is used for faster processing, if it does not (like for machines that do not have a Nvidia GPU), CPU is used\n",
    "# While GPU is faster, CPU is sufficient for this relatively small model\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize W&B project\n",
    "wandb.init(\n",
    "    project=\"it-news-sentiment\",\n",
    "    name=\"bert-inference-full-run-final\",\n",
    "    config={\n",
    "        \"model_name\": \"oliverguhr/german-sentiment-bert\",\n",
    "        \"threshold_negative\": THRESHOLD_NEGATIVE,\n",
    "        \"threshold_positive\": THRESHOLD_POSITIVE,\n",
    "        \"dataset_size\": len(df),\n",
    "        \"batch_size\": 32,\n",
    "        \"device\": device,\n",
    "        \"truncation\": True,\n",
    "        \"max_length\": 512\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916b793-8edc-416c-beea-6d26ed64f9a9",
   "metadata": {},
   "source": [
    "For the sentiment analysis, the german-sentiment-bert model from huggingface was chosen: https://huggingface.co/oliverguhr/german-sentiment-bert. Inference on BERT models runs faster than for generative LLMs while being a lot smaller in size. To analyze the ~50.000 articles, this model is powerful enough without being overkill for the scope of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2726850c-5415-4425-b4a3-e650b309d88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: oliverguhr/german-sentiment-bert ...\n"
     ]
    }
   ],
   "source": [
    "# --- LOAD MODEL ---\n",
    "model_name = \"oliverguhr/german-sentiment-bert\"\n",
    "print(f\"Loading model: {model_name} ...\")\n",
    "\n",
    "# Create a transformers pipeline, which is useful to model inference in a very simple way\n",
    "usegpu = -1 if device == \"cpu\" else 0 # device paramtere for pipeline function accepts -1 for CPU and 0 for GPU\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model_name, device=usegpu, truncation=True, top_k=None) # Use truncation, as start of the article sufficient for sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5d61-20ce-4674-b327-0c09b8f36706",
   "metadata": {},
   "source": [
    "This helper function prepares the text by combining title and text, while only returning the first 2000 characters to speed up tokenizer performance. This is not a problem as the model only sees the first 400-500 words due to truncation, which is sufficient to analyse the sentiment of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d8d5e5b-7a2e-4de8-9d09-5ce314eeac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HELPER FUNCTION ---\n",
    "\n",
    "def prepare_text(row):\n",
    "    \n",
    "    # Combine title and text\n",
    "    title = str(row['Title']) if pd.notna(row['Title']) else \"\"\n",
    "    text = str(row['Text']) if pd.notna(row['Text']) else \"\" \n",
    "    combined = title + \". \" + text\n",
    "    # Shorten combined text to 2000 characters to improve performance\n",
    "    return combined[:2000] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e789c08-e64e-4803-8a57-7ac4b8f70fdc",
   "metadata": {},
   "source": [
    "This helper function is utilized to classify articles according to the custom sentiment threshold defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0fc0ec-b131-4150-bdf0-38b54c5e8509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HELPER FUNCTION 2 ---\n",
    "\n",
    "def apply_custom_logic(scores_list):\n",
    "\n",
    "    # The input for this function are the raw scores (e.g. {'label': 'neutral', 'score': 0.6})\n",
    "    # First, we transform these into a simple dictionary: {'neutral': 0.6}\n",
    "    scores = {item['label']: item['score'] for item in scores_list}\n",
    "\n",
    "    # From the dict, we extract the positive and negative score\n",
    "    neg_score = scores.get('negative', 0)\n",
    "    pos_score = scores.get('positive', 0)\n",
    "    \n",
    "    # We first check for the negative score, as this will more often be large enough than the positive score\n",
    "    if neg_score >= THRESHOLD_NEGATIVE:\n",
    "        # Check if the sentiment is still more positive than negative (e.g. neg: 0.35, pos: 0.6)\n",
    "        if pos_score > neg_score:\n",
    "            return 'positive', pos_score\n",
    "        return 'negative', neg_score\n",
    "        \n",
    "    if pos_score >= THRESHOLD_POSITIVE:\n",
    "        return 'positive', pos_score\n",
    "        \n",
    "    # If no threshholds were exceeded, return the label with the hjighest score (neutral)\n",
    "    max_label = max(scores, key=scores.get)\n",
    "    return max_label, scores[max_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c8eb0e-8688-4fd7-9c97-d7854c2978ee",
   "metadata": {},
   "source": [
    "The final preparation steps are to apply the prepare text function, set the batch size and results arrays. If you do not want to run the analysis on the entire dataset, uncomment the line to only use the head of the DataFrame to only analyze e.g. 50 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2594663-ae37-4dd9-929d-4522e8e1dfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare text (shortening to 2000 characters)...\n",
      "Setup complete. Ready to start sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "# --- PREPARATION ---\n",
    "\n",
    "df_analyze = df.copy()\n",
    "#df_analyze = df.head(50).copy() #WAS USED AS A TEST RUN, CAN BE UNCOMMENTED AND ADJUSTED TO USE LESS ARTICLES\n",
    "\n",
    "# Prepare text using helper function above\n",
    "print(\"Prepare text (shortening to 2000 characters)...\")\n",
    "texts_to_analyze = df_analyze.apply(prepare_text, axis=1).tolist()\n",
    "\n",
    "# Set batch size and results list\n",
    "batch_size = 32\n",
    "final_labels = []\n",
    "final_scores = []\n",
    "print(\"Setup complete. Ready to start sentiment analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465e6d8-2644-406b-bdd9-bfc39e7af6ac",
   "metadata": {},
   "source": [
    "Now, this cell performs the actual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "474bf477-d28f-41f9-a4b7-e1325d9d9753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160a4aecccfc41f8ba5ed07ab0ef7d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- RUN THE ANALYSIS ---\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Loops through all texts to analyze batch per batch\n",
    "for i in tqdm(range(0, len(texts_to_analyze), batch_size)):\n",
    "    batch = texts_to_analyze[i : i + batch_size]\n",
    "    \n",
    "    try:\n",
    "        # Pipeline gibt jetzt Listen von Listen zurück (wegen top_k=None)\n",
    "        # The pipeline returns lists of lists, with the labels and scores for each article \n",
    "        batch_results_raw = sentiment_pipeline(batch)\n",
    "        \n",
    "        # Use helper function to classify the sentiment of each article\n",
    "        for result_list in batch_results_raw:\n",
    "            label, score = apply_custom_logic(result_list)\n",
    "            final_labels.append(label)\n",
    "            final_scores.append(score)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}: {e}\")\n",
    "        final_labels.extend(['error'] * len(batch))\n",
    "        final_scores.extend([0.0] * len(batch))\n",
    "    \n",
    "    # W&B logging\n",
    "    if i % (batch_size * 10) == 0:\n",
    "        wandb.log({\"progress\": (i / len(texts_to_analyze)) * 100})\n",
    "\n",
    "# Stop time\n",
    "wandb.log({\"duration_seconds\": time.time() - start_time})\n",
    "duration = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5885d-aa6b-4e9d-ab40-520549ae2c6c",
   "metadata": {},
   "source": [
    "Finally, we have the sentiment label and score for each article. All that is left to do is to add them as new columns to the dataframe, save the results to a csv file and finish the Weights and Biases run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73020d03-b0b8-456b-bbd8-a0869b600117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "File saved at:\n",
      "../data/csv/corpus_with_sentiment_sensitive.csv\n",
      "------------------------------------------------------------\n",
      "Sentiment_Label\n",
      "neutral     47676\n",
      "negative     6239\n",
      "positive      218\n",
      "Name: count, dtype: int64\n",
      "W&B Run complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>duration_seconds</td><td>▁</td></tr><tr><td>progress</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>duration_seconds</td><td>16745.90152</td></tr><tr><td>progress</td><td>99.90209</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert-inference-full-run-sensitive</strong> at: <a href='https://wandb.ai/thebestr/it-news-sentiment/runs/vfjanwdk' target=\"_blank\">https://wandb.ai/thebestr/it-news-sentiment/runs/vfjanwdk</a><br> View project at: <a href='https://wandb.ai/thebestr/it-news-sentiment' target=\"_blank\">https://wandb.ai/thebestr/it-news-sentiment</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251222_170725-vfjanwdk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- COMBINE AND SAVE RESULTS ---\n",
    "\n",
    "if len(final_labels) == len(df_analyze):\n",
    "    # Save sentiment label and score as new columns of the dataframe\n",
    "    df_analyze['Sentiment_Label'] = final_labels\n",
    "    df_analyze['Sentiment_Score'] = final_scores\n",
    "    \n",
    "    # Save final csv corpus\n",
    "    df_analyze.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"File saved at:\\n{OUTPUT_FILE}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Give a short overview on the sentiment distribution\n",
    "    print(df['Sentiment_Label'].value_counts())\n",
    "    \n",
    "    # Log distribution as W&B table\n",
    "    sentiment_counts = df_analyze['Sentiment_Label'].value_counts()\n",
    "    data = [[label, count] for label, count in sentiment_counts.items()]\n",
    "    table = wandb.Table(data=data, columns=[\"label\", \"count\"])\n",
    "    wandb.log({\"sentiment_distribution_sensitive\": wandb.plot.bar(table, \"label\", \"count\")})\n",
    "    print(\"W&B Run complete.\")\n",
    "    \n",
    "# Throw error if size of output does not match input size\n",
    "else:\n",
    "    print(\"Error: Result size does not match corpus size.\")\n",
    "    print(f\"Articles: {len(df_analyze)}, Results: {len(final_labels)}\")\n",
    "\n",
    "# Finish W&B run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d0a4fe-a3c7-451f-b2b8-ca07f217376b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
